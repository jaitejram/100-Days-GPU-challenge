{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgPpV71K_D1y",
        "outputId": "3d8da0e0-660d-4549-b30e-245e0298a5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing kernel.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile kernel.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kernel.cu\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdio> // Include for printf\n",
        "\n",
        "#ifndef M_PI\n",
        "#define M_PI 3.14159265358979323846\n",
        "#endif\n",
        "\n",
        "// Define number of clusters and data points\n",
        "#define NUM_CLUSTERS 2\n",
        "#define N 1024\n",
        "#define THREADS_PER_BLOCK 256\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t error = call; \\\n",
        "        if (error != cudaSuccess) { \\\n",
        "            std::cerr << \"CUDA Error: \" << cudaGetErrorString(error) \\\n",
        "                      << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "__global__ void eStepKernel(float* data, int N_data, float* mu, float* sigma,\n",
        "                           float* pival, float* responsibilities) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < N_data) {\n",
        "        float x = data[idx];\n",
        "        float probs[NUM_CLUSTERS];\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        // printf(\"E-step: idx = %d, x = %f\\n\", idx, x); // Added printf\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            // printf(\"E-step: Cluster %d, mu = %f, sigma = %f, pival = %f\\n\", k, mu[k], sigma[k], pival[k]); // Added printf\n",
        "            float diff = x - mu[k];\n",
        "            float exponent = -0.5f * (diff * diff) / (sigma[k] * sigma[k]);\n",
        "            float gauss = (1.0f / (sqrtf(2.0f * M_PI) * sigma[k])) * expf(exponent);\n",
        "            probs[k] = pival[k] * gauss;\n",
        "            sum += probs[k];\n",
        "            // printf(\"E-step: Cluster %d, diff = %f, exponent = %f, gauss = %f, prob = %f, sum = %f\\n\", k, diff, exponent, gauss, probs[k], sum); // Added printf\n",
        "        }\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            responsibilities[idx * NUM_CLUSTERS + k] = probs[k] / sum;\n",
        "            // printf(\"E-step: idx = %d, Cluster %d, responsibility = %f\\n\", idx, k, responsibilities[idx * NUM_CLUSTERS + k]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "__global__ void mStepKernel(float* data, int N_data, float* responsibilities,\n",
        "                           float* sum_gamma, float* sum_x, float* sum_x2) {\n",
        "    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (idx < N_data) {\n",
        "        float x = data[idx];\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            float gamma = responsibilities[idx * NUM_CLUSTERS + k];\n",
        "            atomicAdd(&sum_gamma[k], gamma);\n",
        "            atomicAdd(&sum_x[k], gamma * x);\n",
        "            atomicAdd(&sum_x2[k], gamma * x * x);\n",
        "            // printf(\"M-step: idx = %d, Cluster = %d, gamma = %f, sum_gamma = %f, sum_x = %f, sum_x2 = %f\\n\", idx, k, gamma, sum_gamma[k], sum_x[k], sum_x2[k]); // Added printf\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Seed the random number generator\n",
        "    srand(static_cast<unsigned>(time(NULL)));\n",
        "\n",
        "    float h_data[N];\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (i < N/2) {\n",
        "            h_data[i] = 2.0f + static_cast<float>(rand()) / RAND_MAX;\n",
        "        } else {\n",
        "            h_data[i] = 8.0f + static_cast<float>(rand()) / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Initial parameters (host)\n",
        "    float h_mu[NUM_CLUSTERS] = {1.0f, 9.0f};\n",
        "    float h_sigma[NUM_CLUSTERS] = {1.0f, 1.0f};\n",
        "    float h_pival[NUM_CLUSTERS] = {0.5f, 0.5f};\n",
        "\n",
        "    float *d_data, *d_mu, *d_sigma, *d_pival;\n",
        "    float *d_responsibilities, *d_sum_gamma, *d_sum_x, *d_sum_x2;\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&d_data, N * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_mu, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sigma, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_pival, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_responsibilities, N * NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_gamma, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_x, NUM_CLUSTERS * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sum_x2, NUM_CLUSTERS * sizeof(float)));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(d_data, h_data, N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    int blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "\n",
        "    float h_sum_gamma[NUM_CLUSTERS];\n",
        "    float h_sum_x[NUM_CLUSTERS];\n",
        "    float h_sum_x2[NUM_CLUSTERS];\n",
        "\n",
        "    // EM iterations\n",
        "    int maxIter = 100;\n",
        "    for (int iter = 0; iter < maxIter; iter++) {\n",
        "\n",
        "        eStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_mu, d_sigma,\n",
        "                                                  d_pival, d_responsibilities);\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "        CUDA_CHECK(cudaMemset(d_sum_gamma, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "        CUDA_CHECK(cudaMemset(d_sum_x, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "        CUDA_CHECK(cudaMemset(d_sum_x2, 0, NUM_CLUSTERS * sizeof(float)));\n",
        "\n",
        "        mStepKernel<<<blocks, THREADS_PER_BLOCK>>>(d_data, N, d_responsibilities,\n",
        "                                                  d_sum_gamma, d_sum_x, d_sum_x2);\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_gamma, d_sum_gamma, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_x, d_sum_x, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "        CUDA_CHECK(cudaMemcpy(h_sum_x2, d_sum_x2, NUM_CLUSTERS * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "            if (h_sum_gamma[k] > 1e-6f) {\n",
        "                // Update mean\n",
        "                h_mu[k] = h_sum_x[k] / h_sum_gamma[k];\n",
        "\n",
        "\n",
        "                float variance = h_sum_x2[k] / h_sum_gamma[k] - h_mu[k] * h_mu[k];\n",
        "                h_sigma[k] = sqrtf(fmax(variance, 1e-6f));\n",
        "\n",
        "                h_pival[k] = h_sum_gamma[k] / N;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(d_mu, h_mu, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(d_sigma, h_sigma, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(d_pival, h_pival, NUM_CLUSTERS * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "        if (iter % 10 == 0) {\n",
        "            std::cout << \"Iteration \" << iter << \":\\n\";\n",
        "            for (int k = 0; k < NUM_CLUSTERS; k++) {\n",
        "                std::cout << \"Cluster \" << k << \": \"\n",
        "                         << \"mu = \" << h_mu[k] << \", \"\n",
        "                         << \"sigma = \" << h_sigma[k] << \", \"\n",
        "                         << \"pi = \" << h_pival[k] << std::endl;\n",
        "            }\n",
        "            std::cout << std::endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(d_mu);\n",
        "    cudaFree(d_sigma);\n",
        "    cudaFree(d_pival);\n",
        "    cudaFree(d_responsibilities);\n",
        "    cudaFree(d_sum_gamma);\n",
        "    cudaFree(d_sum_x);\n",
        "    cudaFree(d_sum_x2);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWzXwc-x_Lz2",
        "outputId": "1b871d7f-ae28-4a04-9f47-9f17cf022b1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc kernel.cu -o kernel -gencode arch=compute_75,code=sm_75 -lcublas\n",
        "\n",
        "!/content/kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke0GC0wB_TM5",
        "outputId": "617acc09-943d-4b64-9317-267433c3b8be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.296621, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.29203, pi = 0.5\n",
            "\n",
            "Iteration 10:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.296624, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292069, pi = 0.5\n",
            "\n",
            "Iteration 20:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292069, pi = 0.5\n",
            "\n",
            "Iteration 30:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292056, pi = 0.5\n",
            "\n",
            "Iteration 40:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292056, pi = 0.5\n",
            "\n",
            "Iteration 50:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292056, pi = 0.5\n",
            "\n",
            "Iteration 60:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292056, pi = 0.5\n",
            "\n",
            "Iteration 70:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.296624, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292069, pi = 0.5\n",
            "\n",
            "Iteration 80:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.29662, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292056, pi = 0.5\n",
            "\n",
            "Iteration 90:\n",
            "Cluster 0: mu = 2.51149, sigma = 0.296624, pi = 0.5\n",
            "Cluster 1: mu = 8.49133, sigma = 0.292069, pi = 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPdqVV35_XGt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
