{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8xNTY5VLMxX",
        "outputId": "e60fd00d-f322-4a8e-e43b-2d0cfb4e60cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing swiglu.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile swiglu.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile swiglu.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <random>\n",
        "\n",
        "// Kernel function for SwiGLU\n",
        "__global__ void swiglu_kernel(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
        "    int b = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int o = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (b < batch_size && o < output_dim) {\n",
        "        float xW1 = 0.0f;\n",
        "        float xW2 = 0.0f;\n",
        "\n",
        "        for (int i = 0; i < hidden_dim; i++) {\n",
        "            xW1 += x[b * hidden_dim + i] * W1[o + i * output_dim];\n",
        "            xW2 += x[b * hidden_dim + i] * W2[o + i * output_dim];\n",
        "        }\n",
        "\n",
        "        float sigmoid_val = 1.0f / (1.0f + expf(-xW1));\n",
        "        float result = xW1 * sigmoid_val * xW2;\n",
        "\n",
        "        if (b == 0 && o == 0) {  // Print debug info for first element\n",
        "            printf(\"GPU Debug: xW1=%f, xW2=%f, sigmoid_val=%f, result=%f\\n\",\n",
        "                   xW1, xW2, sigmoid_val, result);\n",
        "        }\n",
        "\n",
        "        out[b * output_dim + o] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "void swiglu_forward(float* out, const float* x, const float* W1, const float* W2, int batch_size, int hidden_dim, int output_dim) {\n",
        "    // Allocate memory on GPU\n",
        "    float *d_x, *d_W1, *d_W2, *d_out;\n",
        "    cudaMalloc((void**)&d_x, batch_size * hidden_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_W1, hidden_dim * output_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_W2, hidden_dim * output_dim * sizeof(float));\n",
        "    cudaMalloc((void**)&d_out, batch_size * output_dim * sizeof(float));\n",
        "\n",
        "    // Copy data to GPU\n",
        "    cudaMemcpy(d_x, x, batch_size * hidden_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_W1, W1, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_W2, W2, hidden_dim * output_dim * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define CUDA kernel launch parameters\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((batch_size + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
        "                       (output_dim + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    swiglu_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_out, d_x, d_W1, d_W2, batch_size, hidden_dim, output_dim);\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"Kernel launch failed: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "\n",
        "    // Copy result back to CPU\n",
        "    cudaMemcpy(out, d_out, batch_size * output_dim * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_x);\n",
        "    cudaFree(d_W1);\n",
        "    cudaFree(d_W2);\n",
        "    cudaFree(d_out);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int batch_size = 32;\n",
        "    int hidden_dim = 128;\n",
        "    int output_dim = 64;\n",
        "\n",
        "    // Allocate memory\n",
        "    float *x = new float[batch_size * hidden_dim];\n",
        "    float *W1 = new float[hidden_dim * output_dim];\n",
        "    float *W2 = new float[hidden_dim * output_dim];\n",
        "    float *out = new float[batch_size * output_dim];\n",
        "\n",
        "    // Initialize random number generator\n",
        "    std::random_device rd;\n",
        "    std::mt19937 gen(rd());\n",
        "    std::uniform_real_distribution<float> dis(0.0f, 1.0f);\n",
        "\n",
        "    // Initialize input data with random values between 0 and 1\n",
        "    for (int i = 0; i < batch_size * hidden_dim; i++) {\n",
        "        x[i] = dis(gen);\n",
        "    }\n",
        "    for (int i = 0; i < hidden_dim * output_dim; i++) {\n",
        "        W1[i] = dis(gen);\n",
        "        W2[i] = dis(gen);\n",
        "    }\n",
        "\n",
        "    // Manual CPU calculation for first element (for verification)\n",
        "    float manual_xW1 = 0.0f;\n",
        "    float manual_xW2 = 0.0f;\n",
        "    for (int i = 0; i < hidden_dim; i++) {\n",
        "        manual_xW1 += x[i] * W1[i * output_dim];\n",
        "        manual_xW2 += x[i] * W2[i * output_dim];\n",
        "    }\n",
        "    std::cout << \"CPU Manual calculation for first element:\" << std::endl;\n",
        "    std::cout << \"xW1: \" << manual_xW1 << std::endl;\n",
        "    std::cout << \"xW2: \" << manual_xW2 << std::endl;\n",
        "    float manual_sigmoid = 1.0f / (1.0f + exp(-manual_xW1));\n",
        "    float manual_result = manual_xW1 * manual_sigmoid * manual_xW2;\n",
        "    std::cout << \"Expected result: \" << manual_result << std::endl;\n",
        "\n",
        "    // Compute SwiGLU\n",
        "    swiglu_forward(out, x, W1, W2, batch_size, hidden_dim, output_dim);\n",
        "\n",
        "    // Print some input values\n",
        "    std::cout << \"\\nFirst 10 input values:\" << std::endl;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"x[\" << i << \"]: \" << x[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"\\nFirst 10 W1 values:\" << std::endl;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"W1[\" << i << \"]: \" << W1[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"\\nFirst 10 W2 values:\" << std::endl;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"W2[\" << i << \"]: \" << W2[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    // Print output values\n",
        "    std::cout << \"\\nFirst 10 output values:\" << std::endl;\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        std::cout << \"out[\" << i << \"]: \" << out[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    delete[] x;\n",
        "    delete[] W1;\n",
        "    delete[] W2;\n",
        "    delete[] out;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWWrmfBqL9YJ",
        "outputId": "163f557d-ba58-40a9-fc33-53c175af4858"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting swiglu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc swiglu.cu -o swiglu -gencode arch=compute_75,code=sm_75 -lcublas\n",
        "\n",
        "!/content/swiglu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbKpShsDMGxU",
        "outputId": "0f206118-da56-4b18-ecb7-8557d9ae2883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Manual calculation for first element:\n",
            "xW1: 32.708\n",
            "xW2: 33.698\n",
            "Expected result: 1102.19\n",
            "Kernel launch failed: CUDA driver version is insufficient for CUDA runtime version\n",
            "\n",
            "First 10 input values:\n",
            "x[0]: 0.665048\n",
            "x[1]: 0.623147\n",
            "x[2]: 0.497072\n",
            "x[3]: 0.466184\n",
            "x[4]: 0.638544\n",
            "x[5]: 0.0159838\n",
            "x[6]: 0.465919\n",
            "x[7]: 0.00488248\n",
            "x[8]: 0.973522\n",
            "x[9]: 0.761896\n",
            "\n",
            "First 10 W1 values:\n",
            "W1[0]: 0.8414\n",
            "W1[1]: 0.425116\n",
            "W1[2]: 0.550404\n",
            "W1[3]: 0.952796\n",
            "W1[4]: 0.10383\n",
            "W1[5]: 0.504409\n",
            "W1[6]: 0.061894\n",
            "W1[7]: 0.2849\n",
            "W1[8]: 0.43247\n",
            "W1[9]: 0.57822\n",
            "\n",
            "First 10 W2 values:\n",
            "W2[0]: 0.485255\n",
            "W2[1]: 0.518524\n",
            "W2[2]: 0.189455\n",
            "W2[3]: 0.660907\n",
            "W2[4]: 0.266557\n",
            "W2[5]: 0.986408\n",
            "W2[6]: 0.877896\n",
            "W2[7]: 0.444746\n",
            "W2[8]: 0.385928\n",
            "W2[9]: 0.0935302\n",
            "\n",
            "First 10 output values:\n",
            "out[0]: 0\n",
            "out[1]: 0\n",
            "out[2]: 0\n",
            "out[3]: 0\n",
            "out[4]: 0\n",
            "out[5]: 0\n",
            "out[6]: 0\n",
            "out[7]: 0\n",
            "out[8]: 0\n",
            "out[9]: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsuUI6-8MR16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
