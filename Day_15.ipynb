{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile cnn.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5lOBGqK0jWI",
        "outputId": "5a8935e1-9bce-4103-d19e-b373fbf55733"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cnn.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVVEJkIm0Ymc",
        "outputId": "6ad8fee5-611d-448a-e0e6-d5a5b2560267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cnn.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cnn.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <cuda.h>\n",
        "#include <cstdlib>\n",
        "#define CUDA_MAX_NUM_THREADS 1024\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// CUDA Kernel for computing dL/dW\n",
        "template <typename T>\n",
        "__global__ void compute_dLdW(T* dLdY, T* input_unrolled, T* dLdW, int output_height, int output_width, int num_filters, int filter_size) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < filter_size && col < num_filters) {\n",
        "        T sum = 0;\n",
        "        for (int i = 0; i < output_height * output_width; i++) {\n",
        "            sum += input_unrolled[i * filter_size + row] * dLdY[i * num_filters + col];\n",
        "        }\n",
        "        dLdW[row * num_filters + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA Kernel for computing dL/dX\n",
        "template <typename T>\n",
        "__global__ void compute_dLdX(T* dLdY, T* weights, T* dLdX_unrolled, int output_height, int output_width, int num_filters, int filter_size) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < output_height * output_width && col < filter_size) {\n",
        "        T sum = 0;\n",
        "        for (int i = 0; i < num_filters; i++) {\n",
        "            sum += dLdY[row * num_filters + i] * weights[col * num_filters + i];\n",
        "        }\n",
        "        dLdX_unrolled[row * filter_size + col] = sum;\n",
        "    }\n",
        "}\n",
        "template <typename T>\n",
        "__global__ void maxPoolingBackwardKernel(T* dLdY, T* input, T* dLdX, int input_height, int input_width, int pool_size, int stride) {\n",
        "    int output_height = (input_height - pool_size) / stride + 1;\n",
        "    int output_width = (input_width - pool_size) / stride + 1;\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < output_height && col < output_width) {\n",
        "        T max_value = -INFINITY;\n",
        "        int max_i = -1, max_j = -1;\n",
        "        for (int i = 0; i < pool_size; i++) {\n",
        "            for (int j = 0; j < pool_size; j++) {\n",
        "                int input_row = row * stride + i;\n",
        "                int input_col = col * stride + j;\n",
        "\n",
        "                // Access input correctly, avoid out-of-bounds access\n",
        "                if (input_row < input_height && input_col < input_width) {\n",
        "                    if (input[input_row * input_width + input_col] > max_value) {\n",
        "                        max_value = input[input_row * input_width + input_col];\n",
        "                        max_i = input_row;\n",
        "                        max_j = input_col;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Ensure max_i and max_j are valid before accessing dLdX\n",
        "        if (max_i != -1 && max_j != -1) {\n",
        "            atomicAdd(&dLdX[max_i * input_width + max_j], dLdY[row * output_width + col]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Updated kernel signatures to match the calling convention\n",
        "__global__ void unrollKernel(const float* input, float* input_unrolled,\n",
        "                            const int input_channels, const int input_height, const int input_width,\n",
        "                            const int kernel_size, const int output_height, const int output_width) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_elements = output_height * output_width;\n",
        "\n",
        "    if (idx < total_elements) {\n",
        "        int out_y = idx / output_width;\n",
        "        int out_x = idx % output_width;\n",
        "\n",
        "        for (int c = 0; c < input_channels; c++) {\n",
        "            for (int ky = 0; ky < kernel_size; ky++) {\n",
        "                for (int kx = 0; kx < kernel_size; kx++) {\n",
        "                    int in_y = out_y + ky;\n",
        "                    int in_x = out_x + kx;\n",
        "\n",
        "                    int unroll_idx = idx * (input_channels * kernel_size * kernel_size) +\n",
        "                                   (c * kernel_size * kernel_size + ky * kernel_size + kx);\n",
        "\n",
        "                    int input_idx = c * (input_height * input_width) +\n",
        "                                  in_y * input_width + in_x;\n",
        "\n",
        "                    input_unrolled[unroll_idx] = input[input_idx];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// Host function to launch Unrolling Kernel\n",
        "void unrollInput(int input_channels, int input_height, int input_width,\n",
        "                int kernel_size, float* input, float* input_unrolled) {\n",
        "    int output_height = input_height - kernel_size + 1;\n",
        "    int output_width = input_width - kernel_size + 1;\n",
        "    int total_output_elements = output_height * output_width;\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int numBlocks = (total_output_elements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    unrollKernel<<<numBlocks, threadsPerBlock>>>(\n",
        "        input,                  // const float* input\n",
        "        input_unrolled,        // float* input_unrolled\n",
        "        input_channels,        // const int input_channels\n",
        "        input_height,          // const int input_height\n",
        "        input_width,           // const int input_width\n",
        "        kernel_size,           // const int kernel_size\n",
        "        output_height,         // const int output_height\n",
        "        output_width          // const int output_width\n",
        "    );\n",
        "\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        printf(\"CUDA error in unroll: %s\\n\", cudaGetErrorString(error));\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "}\n",
        "\n",
        "void convolutionBackward(int batch_size, int num_filters, int input_channels, int input_height, int input_width, int kernel_size, float* dLdY, float* input, float* weights, float* dLdX, float* dLdW) {\n",
        "    int output_height = input_height - kernel_size + 1;\n",
        "    int output_width = input_width - kernel_size + 1;\n",
        "    int filter_size = input_channels * kernel_size * kernel_size;\n",
        "\n",
        "    float* input_unrolled;\n",
        "    float* dLdX_unrolled;\n",
        "    cudaMalloc(&input_unrolled, output_height * output_width * filter_size * sizeof(float));\n",
        "    cudaMalloc(&dLdX_unrolled, output_height * output_width * filter_size * sizeof(float));\n",
        "\n",
        "    for (int n = 0; n < batch_size; n++) {\n",
        "        unrollInput(input_channels, input_height, input_width, kernel_size, input + n * input_channels * input_height * input_width, input_unrolled);\n",
        "\n",
        "        dim3 blockSize(16, 16);\n",
        "        dim3 gridSize((output_width + blockSize.x - 1) / blockSize.x, (output_height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "        compute_dLdW<<<gridSize, blockSize>>>(dLdY, input_unrolled, dLdW, output_height, output_width, num_filters, filter_size);\n",
        "        compute_dLdX<<<gridSize, blockSize>>>(dLdY, weights, dLdX_unrolled, output_height, output_width, num_filters, filter_size);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    cudaFree(input_unrolled);\n",
        "    cudaFree(dLdX_unrolled);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "// CUDA Kernel for Max Pooling\n",
        "__global__ void maxPoolingKernel(float* input, float* output, int input_height, int input_width, int pool_size, int stride) {\n",
        "    int output_height = (input_height - pool_size) / stride + 1;\n",
        "    int output_width = (input_width - pool_size) / stride + 1;\n",
        "\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < output_height && col < output_width) {\n",
        "        float max_value = -INFINITY;\n",
        "        for (int i = 0; i < pool_size; i++) {\n",
        "            for (int j = 0; j < pool_size; j++) {\n",
        "                int input_row = row * stride + i;\n",
        "                int input_col = col * stride + j;\n",
        "                max_value = fmaxf(max_value, input[input_row * input_width + input_col]);\n",
        "            }\n",
        "        }\n",
        "        output[row * output_width + col] = max_value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA Kernel for Matrix Multiplication (GEMM for Convolution)\n",
        "__global__ void matrixMultiplicationKernel(float* input_unrolled, float* weights, float* output,\n",
        "                                         int output_height, int output_width, int num_filters, int filter_size) {\n",
        "    // Calculate actual position\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int total_output_elements = output_height * output_width;\n",
        "\n",
        "    if (idx < total_output_elements * num_filters) {\n",
        "        int output_idx = idx / num_filters;  // Position in output feature map\n",
        "        int filter_idx = idx % num_filters;  // Which filter we're using\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        // Multiply unrolled input with the corresponding filter\n",
        "        for (int i = 0; i < filter_size; i++) {\n",
        "            sum += input_unrolled[output_idx * filter_size + i] * weights[i * num_filters + filter_idx];\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__global__ void convolutionKernel(const float* input_unrolled, const float* weights, float* output,\n",
        "                                 const int output_size, const int num_filters, const int filter_size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < output_size * num_filters) {\n",
        "        int output_idx = idx / num_filters;\n",
        "        int filter_idx = idx % num_filters;\n",
        "\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < filter_size; i++) {\n",
        "            sum += input_unrolled[output_idx * filter_size + i] *\n",
        "                   weights[i * num_filters + filter_idx];\n",
        "        }\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void convolutionForward(float* input, float* weights, float* output,\n",
        "                       int batch_size, int num_filters, int input_channels,\n",
        "                       int input_height, int input_width, int kernel_size) {\n",
        "    int output_height = input_height - kernel_size + 1;\n",
        "    int output_width = input_width - kernel_size + 1;\n",
        "    int output_size = output_height * output_width;\n",
        "    int filter_size = input_channels * kernel_size * kernel_size;\n",
        "\n",
        "    // Allocate unrolled input matrix\n",
        "    float* input_unrolled;\n",
        "    size_t unrolled_size = output_size * filter_size * sizeof(float);\n",
        "    cudaMalloc(&input_unrolled, unrolled_size);\n",
        "\n",
        "    // Calculate grid and block dimensions\n",
        "    int unroll_blocks = (output_size + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    int conv_blocks = (output_size * num_filters + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    for (int n = 0; n < batch_size; n++) {\n",
        "        float* input_n = input + n * input_channels * input_height * input_width;\n",
        "        float* output_n = output + n * num_filters * output_height * output_width;\n",
        "\n",
        "        // Launch unroll kernel with correct parameters\n",
        "        unrollKernel<<<unroll_blocks, BLOCK_SIZE>>>(\n",
        "            input_n,\n",
        "            input_unrolled,\n",
        "            input_channels,\n",
        "            input_height,\n",
        "            input_width,\n",
        "            kernel_size,\n",
        "            output_height,\n",
        "            output_width\n",
        "        );\n",
        "\n",
        "        // Check for kernel launch errors\n",
        "        cudaError_t error = cudaGetLastError();\n",
        "        if (error != cudaSuccess) {\n",
        "            printf(\"Unroll kernel error: %s\\n\", cudaGetErrorString(error));\n",
        "        }\n",
        "\n",
        "        // Launch convolution kernel\n",
        "        convolutionKernel<<<conv_blocks, BLOCK_SIZE>>>(\n",
        "            input_unrolled,\n",
        "            weights,\n",
        "            output_n,\n",
        "            output_size,\n",
        "            num_filters,\n",
        "            filter_size\n",
        "        );\n",
        "\n",
        "        // Check for kernel launch errors\n",
        "        error = cudaGetLastError();\n",
        "        if (error != cudaSuccess) {\n",
        "            printf(\"Convolution kernel error: %s\\n\", cudaGetErrorString(error));\n",
        "        }\n",
        "\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    cudaFree(input_unrolled);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Running CNN CUDA kernels...\\n\");\n",
        "\n",
        "    // Optional: test function\n",
        "    // testConvNet();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cnn.cu -o cnn -gencode arch=compute_75,code=sm_75 -lcurand\n",
        "\n",
        "!./cnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RipRBk110pzQ",
        "outputId": "8773e1ea-88b9-489e-8e9e-f771d10d5850"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running CNN CUDA kernels...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrb2NgN74NIb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
