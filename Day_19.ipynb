{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjBl0QXyjRMK",
        "outputId": "60badc92-906c-40d3-a472-a43804ad3156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fcnet.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile fcnet.cu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fcnet.cu\n",
        "#include <cudnn.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <curand.h>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <iostream>\n",
        "#include <cstdio> // Include for printf\n",
        "\n",
        "#define CHECK_CUDA(func) { \\\n",
        "    cudaError_t status = (func); \\\n",
        "    if (status != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error at \" << __FILE__ << \":\" << __LINE__ << \" - \" << cudaGetErrorString(status) << std::endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUDNN(func) { \\\n",
        "    cudnnStatus_t status = (func); \\\n",
        "    if (status != CUDNN_STATUS_SUCCESS) { \\\n",
        "        std::cerr << \"cuDNN Error at \" << __FILE__ << \":\" << __LINE__ << \" - \" << cudnnGetErrorString(status) << std::endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "// Network parameters\n",
        "const int input_size = 1000;\n",
        "const int hidden_size = 512;\n",
        "const int output_size = 10;\n",
        "const int batch_size = 64;\n",
        "//const float learning_rate = 0.001f;\n",
        "const int epochs = 10;\n",
        "\n",
        "// Helper function to initialize weights\n",
        "void initialize_weights(float* weights, int size) {\n",
        "    curandGenerator_t gen;\n",
        "    curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT);\n",
        "    curandSetPseudoRandomGeneratorSeed(gen, time(NULL));\n",
        "    curandGenerateUniform(gen, weights, size);\n",
        "    curandDestroyGenerator(gen);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Initializing CUDA and cuDNN...\\n\");\n",
        "    // Initialize CUDA and cuDNN\n",
        "    cudnnHandle_t cudnn;\n",
        "    CHECK_CUDNN(cudnnCreate(&cudnn));\n",
        "    printf(\"CUDA and cuDNN initialized.\\n\");\n",
        "\n",
        "    // Create tensor descriptors\n",
        "    printf(\"Creating tensor descriptors...\\n\");\n",
        "    cudnnTensorDescriptor_t input_desc, hidden1_desc, hidden2_desc, output_desc;\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&input_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&hidden1_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&hidden2_desc));\n",
        "    CHECK_CUDNN(cudnnCreateTensorDescriptor(&output_desc));\n",
        "    printf(\"Tensor descriptors created.\\n\");\n",
        "\n",
        "    // Set tensor dimensions (NCHW format)\n",
        "    printf(\"Setting tensor dimensions...\\n\");\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, input_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(hidden1_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, hidden_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(hidden2_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, hidden_size, 1, 1));\n",
        "    CHECK_CUDNN(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT,\n",
        "                                          batch_size, output_size, 1, 1));\n",
        "    printf(\"Tensor dimensions set.\\n\");\n",
        "\n",
        "    // Create filter descriptors (weights)\n",
        "    printf(\"Creating filter descriptors...\\n\");\n",
        "    cudnnFilterDescriptor_t fc1_w_desc, fc2_w_desc, fc3_w_desc;\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc1_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc1_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          hidden_size, input_size, 1, 1));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc2_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc2_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          hidden_size, hidden_size, 1, 1));\n",
        "\n",
        "    CHECK_CUDNN(cudnnCreateFilterDescriptor(&fc3_w_desc));\n",
        "    CHECK_CUDNN(cudnnSetFilter4dDescriptor(fc3_w_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW,\n",
        "                                          output_size, hidden_size, 1, 1));\n",
        "    printf(\"Filter descriptors created.\\n\");\n",
        "\n",
        "    // Create activation descriptor (ReLU)\n",
        "    printf(\"Creating activation descriptor...\\n\");\n",
        "    cudnnActivationDescriptor_t relu_desc;\n",
        "    CHECK_CUDNN(cudnnCreateActivationDescriptor(&relu_desc));\n",
        "    CHECK_CUDNN(cudnnSetActivationDescriptor(relu_desc, CUDNN_ACTIVATION_RELU,\n",
        "                                             CUDNN_NOT_PROPAGATE_NAN, 0.0));\n",
        "    printf(\"Activation descriptor created.\\n\");\n",
        "\n",
        "    // Allocate device memory\n",
        "    printf(\"Allocating device memory...\\n\");\n",
        "    float *d_input, *d_labels, *d_output;\n",
        "    CHECK_CUDA(cudaMalloc(&d_input, batch_size * input_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_labels, batch_size * output_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_output, batch_size * output_size * sizeof(float)));\n",
        "    printf(\"Device memory allocated.\\n\");\n",
        "\n",
        "    // Initialize weights and biases\n",
        "    printf(\"Initializing weights and biases...\\n\");\n",
        "    float *d_w1, *d_b1, *d_w2, *d_b2, *d_w3, *d_b3;\n",
        "    CHECK_CUDA(cudaMalloc(&d_w1, hidden_size * input_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b1, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_w2, hidden_size * hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b2, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_w3, output_size * hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b3, output_size * sizeof(float)));\n",
        "\n",
        "    initialize_weights(d_w1, hidden_size * input_size);\n",
        "    initialize_weights(d_w2, hidden_size * hidden_size);\n",
        "    initialize_weights(d_w3, output_size * hidden_size);\n",
        "    CHECK_CUDA(cudaMemset(d_b1, 0, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMemset(d_b2, 0, hidden_size * sizeof(float)));\n",
        "    CHECK_CUDA(cudaMemset(d_b3, 0, output_size * sizeof(float)));\n",
        "    printf(\"Weights and biases initialized.\\n\");\n",
        "\n",
        "    // Generate dummy data\n",
        "    printf(\"Generating dummy data...\\n\");\n",
        "    initialize_weights(d_input, batch_size * input_size);\n",
        "    initialize_weights(d_labels, batch_size * output_size);\n",
        "    printf(\"Dummy data generated.\\n\");\n",
        "\n",
        "    // Create convolution descriptors\n",
        "    printf(\"Creating convolution descriptor...\\n\");\n",
        "    cudnnConvolutionDescriptor_t conv_desc;\n",
        "    CHECK_CUDNN(cudnnCreateConvolutionDescriptor(&conv_desc));\n",
        "    CHECK_CUDNN(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1,\n",
        "                                               CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));\n",
        "    printf(\"Convolution descriptor created.\\n\");\n",
        "\n",
        "    // Training loop\n",
        "    printf(\"Starting training loop for %d epochs...\\n\", epochs);\n",
        "    for (int epoch = 0; epoch < epochs; ++epoch) {\n",
        "        printf(\"Epoch %d/%d\\n\", epoch + 1, epochs);\n",
        "        // Forward pass\n",
        "        float alpha = 1.0f, beta = 0.0f;\n",
        "        float* d_hidden1, *d_hidden2;\n",
        "        CHECK_CUDA(cudaMalloc(&d_hidden1, batch_size * hidden_size * sizeof(float)));\n",
        "        CHECK_CUDA(cudaMalloc(&d_hidden2, batch_size * hidden_size * sizeof(float)));\n",
        "\n",
        "        // Layer 1: Input -> Hidden1\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           input_desc, d_input,\n",
        "                                           fc1_w_desc, d_w1,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           hidden1_desc, d_hidden1));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, hidden1_desc, d_b1,\n",
        "                                  &alpha, hidden1_desc, d_hidden1));\n",
        "        CHECK_CUDNN(cudnnActivationForward(cudnn, relu_desc,\n",
        "                                          &alpha, hidden1_desc, d_hidden1,\n",
        "                                          &beta, hidden1_desc, d_hidden1));\n",
        "\n",
        "        // Layer 2: Hidden1 -> Hidden2\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           hidden1_desc, d_hidden1,\n",
        "                                           fc2_w_desc, d_w2,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           hidden2_desc, d_hidden2));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, hidden2_desc, d_b2,\n",
        "                                  &alpha, hidden2_desc, d_hidden2));\n",
        "        CHECK_CUDNN(cudnnActivationForward(cudnn, relu_desc,\n",
        "                                          &alpha, hidden2_desc, d_hidden2,\n",
        "                                          &beta, hidden2_desc, d_hidden2));\n",
        "\n",
        "        // Layer 3: Hidden2 -> Output\n",
        "        CHECK_CUDNN(cudnnConvolutionForward(cudnn, &alpha,\n",
        "                                           hidden2_desc, d_hidden2,\n",
        "                                           fc3_w_desc, d_w3,\n",
        "                                           conv_desc,\n",
        "                                           CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM,\n",
        "                                           nullptr, 0,\n",
        "                                           &beta,\n",
        "                                           output_desc, d_output));\n",
        "        CHECK_CUDNN(cudnnAddTensor(cudnn, &alpha, output_desc, d_b3,\n",
        "                                  &alpha, output_desc, d_output));\n",
        "\n",
        "        // Cleanup intermediate buffers\n",
        "        CHECK_CUDA(cudaFree(d_hidden1));\n",
        "        CHECK_CUDA(cudaFree(d_hidden2));\n",
        "\n",
        "        // Inference (example)\n",
        "        if (epoch == epochs - 1) {\n",
        "            float* h_output = new float[batch_size * output_size];\n",
        "            CHECK_CUDA(cudaMemcpy(h_output, d_output, batch_size * output_size * sizeof(float),\n",
        "                                 cudaMemcpyDeviceToHost));\n",
        "            std::cout << \"Final inference results sample: \" << h_output[0] << std::endl;\n",
        "            delete[] h_output;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Training loop finished.\\n\"); // Added printf\n",
        "\n",
        "    // Cleanup\n",
        "    printf(\"Cleaning up device memory and cuDNN resources...\\n\"); // Added printf\n",
        "    CHECK_CUDA(cudaFree(d_input));\n",
        "    CHECK_CUDA(cudaFree(d_labels));\n",
        "    CHECK_CUDA(cudaFree(d_output));\n",
        "    CHECK_CUDA(cudaFree(d_w1));\n",
        "    CHECK_CUDA(cudaFree(d_b1));\n",
        "    CHECK_CUDA(cudaFree(d_w2));\n",
        "    CHECK_CUDA(cudaFree(d_b2));\n",
        "    CHECK_CUDA(cudaFree(d_w3));\n",
        "    CHECK_CUDA(cudaFree(d_b3));\n",
        "\n",
        "    CHECK_CUDNN(cudnnDestroyConvolutionDescriptor(conv_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyActivationDescriptor(relu_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc1_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc2_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyFilterDescriptor(fc3_w_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(input_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(hidden1_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(hidden2_desc));\n",
        "    CHECK_CUDNN(cudnnDestroyTensorDescriptor(output_desc));\n",
        "    CHECK_CUDNN(cudnnDestroy(cudnn));\n",
        "    printf(\"Cleanup complete.\\n\"); // Added printf\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZqm2hRulv8y",
        "outputId": "abd6faac-2750-4015-ae97-ee264c77a1a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fcnet.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc fcnet.cu -o fcnet -gencode arch=compute_75,code=sm_75 -lcublas -lcudnn -lcurand\n",
        "\n",
        "!./fcnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeVIIobcsrrz",
        "outputId": "918107c8-b074-4d4d-cb0a-49a17406c5d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing CUDA and cuDNN...\n",
            "CUDA and cuDNN initialized.\n",
            "Creating tensor descriptors...\n",
            "Tensor descriptors created.\n",
            "Setting tensor dimensions...\n",
            "Tensor dimensions set.\n",
            "Creating filter descriptors...\n",
            "Filter descriptors created.\n",
            "Creating activation descriptor...\n",
            "Activation descriptor created.\n",
            "Allocating device memory...\n",
            "Device memory allocated.\n",
            "Initializing weights and biases...\n",
            "Weights and biases initialized.\n",
            "Generating dummy data...\n",
            "Dummy data generated.\n",
            "Creating convolution descriptor...\n",
            "Convolution descriptor created.\n",
            "Starting training loop for 10 epochs...\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Final inference results sample: 1.67509e+07\n",
            "Training loop finished.\n",
            "Cleaning up device memory and cuDNN resources...\n",
            "Cleanup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WnQs1BOBsw2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
