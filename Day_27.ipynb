{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile MIRROR.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDC0Qz07TSmd",
        "outputId": "03322fc6-c762-4834-a396-c73268634ceb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting MIRROR.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLlpHwPbS8N5",
        "outputId": "065dd0e3-5c80-4253-8a1d-2131f9e99eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting MIRROR.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile MIRROR.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 1024  // Number of elements\n",
        "#define ETA 0.5f // Larger learning rate\n",
        "\n",
        "// Mirror Maps\n",
        "#define EUCLIDEAN         0  // Standard gradient descent\n",
        "#define NEGATIVE_ENTROPY  1  // Exponentiated gradient descent\n",
        "#define LOG_BARRIER       2  // Positive orthant\n",
        "\n",
        "__global__ void mirror_descent(float *x, float *grad, float eta, int mirror_map, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i >= n) return;\n",
        "\n",
        "    float new_x = x[i];\n",
        "\n",
        "    // Add printf for debugging\n",
        "    if (i < 10) { // Print for the first 10 threads\n",
        "        printf(\"Thread %d: Initial x[%d] = %f, grad[%d] = %f\\n\", i, i, x[i], i, grad[i]);\n",
        "    }\n",
        "\n",
        "    switch (mirror_map) {\n",
        "        case EUCLIDEAN:\n",
        "            new_x = x[i] - eta * grad[i];\n",
        "            break;\n",
        "\n",
        "        case NEGATIVE_ENTROPY:\n",
        "            new_x = x[i] * expf(-eta * grad[i]); // Ensure updates are visible\n",
        "            break;\n",
        "\n",
        "        case LOG_BARRIER:\n",
        "            new_x = x[i] / (1.0f + eta * grad[i]);\n",
        "            break;\n",
        "\n",
        "        default:\n",
        "            new_x = x[i];\n",
        "    }\n",
        "\n",
        "    x[i] = new_x;\n",
        "\n",
        "    // Add printf for debugging after update\n",
        "    if (i < 10) { // Print for the first 10 threads\n",
        "        printf(\"Thread %d: Updated x[%d] = %f\\n\", i, i, x[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkCuda(cudaError_t result, const char *msg) {\n",
        "    if (result != cudaSuccess) {\n",
        "        fprintf(stderr, \"CUDA Error: %s (%s)\\n\", msg, cudaGetErrorString(result));\n",
        "        exit(-1);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *x, *grad, *d_x, *d_grad;\n",
        "    int mirror_map = NEGATIVE_ENTROPY; // Choose the method\n",
        "\n",
        "    // Allocate memory\n",
        "    x = (float*)malloc(N * sizeof(float));\n",
        "    grad = (float*)malloc(N * sizeof(float));\n",
        "    checkCuda(cudaMalloc(&d_x, N * sizeof(float)), \"Alloc d_x\");\n",
        "    checkCuda(cudaMalloc(&d_grad, N * sizeof(float)), \"Alloc d_grad\");\n",
        "\n",
        "    // Initialize x and grad\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        x[i] = 1.0f;  // Start with x_t = 1\n",
        "        grad[i] = 0.5f * i; // Larger gradient values for visible updates\n",
        "    }\n",
        "\n",
        "    // Copy to GPU\n",
        "    checkCuda(cudaMemcpy(d_x, x, N * sizeof(float), cudaMemcpyHostToDevice), \"Memcpy x -> d_x\");\n",
        "    checkCuda(cudaMemcpy(d_grad, grad, N * sizeof(float), cudaMemcpyHostToDevice), \"Memcpy grad -> d_grad\");\n",
        "\n",
        "    // Kernel execution\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "    mirror_descent<<<numBlocks, blockSize>>>(d_x, d_grad, ETA, mirror_map, N);\n",
        "    checkCuda(cudaDeviceSynchronize(), \"Kernel execution\");\n",
        "\n",
        "    // Copy results back\n",
        "    checkCuda(cudaMemcpy(x, d_x, N * sizeof(float), cudaMemcpyDeviceToHost), \"Memcpy d_x -> x\");\n",
        "\n",
        "    // Print first 10 results\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"Host: x[%d] = %f\\n\", i, x[i]);\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    free(x);\n",
        "    free(grad);\n",
        "    cudaFree(d_x);\n",
        "    cudaFree(d_grad);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc MIRROR.cu -o MIRROR -gencode arch=compute_75,code=sm_75 -lcublas\n",
        "\n",
        "!./MIRROR.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIEgfJppTd6L",
        "outputId": "aa6d8c32-fa9b-4fb5-a04e-0c5a7f30a940"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./MIRROR.cu: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWp7KWZNTsOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcab0b9b",
        "outputId": "6f03fef2-04b8-4a3f-8305-6665064cdfbc"
      },
      "source": [
        "!chmod +x MIRROR\n",
        "!./MIRROR"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0: Initial x[0] = 1.000000, grad[0] = 0.000000\n",
            "Thread 1: Initial x[1] = 1.000000, grad[1] = 0.500000\n",
            "Thread 2: Initial x[2] = 1.000000, grad[2] = 1.000000\n",
            "Thread 3: Initial x[3] = 1.000000, grad[3] = 1.500000\n",
            "Thread 4: Initial x[4] = 1.000000, grad[4] = 2.000000\n",
            "Thread 5: Initial x[5] = 1.000000, grad[5] = 2.500000\n",
            "Thread 6: Initial x[6] = 1.000000, grad[6] = 3.000000\n",
            "Thread 7: Initial x[7] = 1.000000, grad[7] = 3.500000\n",
            "Thread 8: Initial x[8] = 1.000000, grad[8] = 4.000000\n",
            "Thread 9: Initial x[9] = 1.000000, grad[9] = 4.500000\n",
            "Thread 0: Updated x[0] = 1.000000\n",
            "Thread 1: Updated x[1] = 0.778801\n",
            "Thread 2: Updated x[2] = 0.606531\n",
            "Thread 3: Updated x[3] = 0.472367\n",
            "Thread 4: Updated x[4] = 0.367879\n",
            "Thread 5: Updated x[5] = 0.286505\n",
            "Thread 6: Updated x[6] = 0.223130\n",
            "Thread 7: Updated x[7] = 0.173774\n",
            "Thread 8: Updated x[8] = 0.135335\n",
            "Thread 9: Updated x[9] = 0.105399\n",
            "Host: x[0] = 1.000000\n",
            "Host: x[1] = 0.778801\n",
            "Host: x[2] = 0.606531\n",
            "Host: x[3] = 0.472367\n",
            "Host: x[4] = 0.367879\n",
            "Host: x[5] = 0.286505\n",
            "Host: x[6] = 0.223130\n",
            "Host: x[7] = 0.173774\n",
            "Host: x[8] = 0.135335\n",
            "Host: x[9] = 0.105399\n"
          ]
        }
      ]
    }
  ]
}
